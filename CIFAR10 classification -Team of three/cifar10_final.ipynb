{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning (GR5242) Final Project Submission\n",
    "### December 17, 2017\n",
    "### Xinyi Huang (xh2294), Shi (Edwin) Bai (sb3878) and Hongfeng Jiang (hj2443)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1: CIFAR-10 Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to classify images from [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes (airplanes, automobiles, birds, cats, deer, dogs, frogs, horses, ships, and trucks). We will first preprocess the images, then build several convolutional neural networks by applying algorithms we learned from class and from our own research on training set. After that, we compare the performance with validation data for each network, and use the testing data to test the performance of selected model at the end.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data comes with 5 training batches and 1 testing batch, with 10000 data in each batch. For this project, we wish to have a validation set to compare the performance of the trained networks. Thus, we combined the 5 training batches and take 10% (5000 in total) of the pictures from the end of the combined set as the validation set. We keep the testing batch as is to be the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download python version of data from https://www.cs.toronto.edu/~kriz/cifar.html \n",
    "## and save to ./data\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='latin1')\n",
    "    return dict\n",
    "\n",
    "def get_data(train=True, n_val=5000):\n",
    "\n",
    "    ## input all 5 batches\n",
    "    if train == True:\n",
    "        first = True\n",
    "        for i in range(5):\n",
    "            file = \"./data/cifar-10-batches-py/data_batch_\" + str(i+1)\n",
    "            this_batch = unpickle(file)\n",
    "            this_labels = np.array(this_batch[\"labels\"])\n",
    "            this_labels_one_hot = (np.arange(10) == this_labels[:, None]).astype(np.float32)\n",
    "            this_img = this_batch[\"data\"].reshape(-1,3,32,32).transpose(0,2,3,1)\n",
    "            \n",
    "            if first is True:\n",
    "                img = this_img\n",
    "                labels_one_hot = this_labels_one_hot\n",
    "                first = False\n",
    "            \n",
    "            else:\n",
    "                img = np.concatenate((img, this_img), axis=0)\n",
    "                labels_one_hot = np.concatenate((labels_one_hot, this_labels_one_hot), axis=0)\n",
    "        \n",
    "        n = img.shape[0]\n",
    "        \n",
    "        return img[:n-n_val], labels_one_hot[:n-n_val], img[-n_val:], labels_one_hot[-n_val:]\n",
    "    \n",
    "    ## input test batch\n",
    "    else:\n",
    "        file = \"./data/cifar-10-batches-py/test_batch\"\n",
    "        this_batch = unpickle(file)\n",
    "        this_labels = np.array(this_batch[\"labels\"])\n",
    "        labels_one_hot = (np.arange(10) == this_labels[:, None]).astype(np.float32)\n",
    "        img = this_batch[\"data\"].reshape(-1,3,32,32).transpose(0,2,3,1)\n",
    "        \n",
    "    \n",
    "        return img, labels_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = get_data()\n",
    "x_test, y_test = get_data(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data dimensions, and set validation set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 32, 32, 3)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "batch_size = 100\n",
    "train_size = x_train.shape[0]\n",
    "val_size = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhcgUOb8QmfL/AZ091e+L5QfuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12aed9940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "ind = np.random.randint(0,x_train.shape[1],1)[0]\n",
    "plt.imshow(x_train[ind])\n",
    "plt.show()\n",
    "print(y_train[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cross entropy and accuracy, adopted from lecture notes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cross_entropy(logits, y):\n",
    "    softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits, name='cross_ent_terms')\n",
    "    cross_ent = tf.reduce_mean(softmax_cross_entropy, name='cross_ent')\n",
    "    return cross_ent\n",
    "\n",
    "def compute_accuracy(logits, y):\n",
    "    prediction = tf.argmax(logits, 1, name='pred_class')\n",
    "    true_label = tf.argmax(y, 1, name='true_class')\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, true_label), tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 1:  Convolutional Layer -> Mixed Max & Average Pooling -> Fully Connected layer\n",
    "1. **Convolutional Layer:** Applies 5\\*5\\*16 filter and 1\\*1 stride, with ReLU activation function. \n",
    "2. **Mixed Pooling Layer:** Performs max pooling with a 3\\*3 filter and stride of 1 and average pooling with a 3\\*3 filter and stride of 1. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "3. **Fully Connected Layer:** Implements the flatten function to change the dimension and the uses softmax activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic behind this network:\n",
    "This is the first and simplest network we tried.\n",
    "1. For Convolutional Layer, the reason why we used 5\\*5\\*16 filter and 1\\*1 stride is that we would like to capture local features by using relative smaller filter size and move the filter one pixel at a time. Since this model is relative simple and the computation is not that expensive, we care less about producing smaller output volumes spatially by using larger filter size. \n",
    "\n",
    "2. We learned from class that pooling is a very common and important trick of the trade. People often use this intermediate layer as a subsampling layer which represent more robust to the effects of variations in data while still remaining the expressivity. Therefore we decided to add one pooling layer after the convolutional layer as it is a very good way to control overfitting. However, there are many options for us and the most commonly used are max pooling and average pooling. We considered a lot about which pooling method we should use in this project. Should we care more about the precise location or relative location to the other features? In our project, we combined max and average pooling functions to improve performance of our network. We got inspired by the paper called *[‘Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree’ written by Chen-Yu Lee, Patrick W. Gallagher and Zhuowen Tu](https://arxiv.org/pdf/1509.08985.pdf)*. To be more specific, we used 50/50 mix, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. We used this method because the classification error (in %) of 50/50 mix is smaller than the error of baseline model (trained with conventional max pooling). The statistics are shown in the Table 1 of this paper and the classification error (in %) of 50/50 mix is $8.11\\pm 0.10$ while the classification error of baseline is 9.10. Another nice thing of this method is that there is only a light increase in computational overhead during training but it has a relative large increase in the performance. \n",
    "\n",
    "3. The output from convolutional and pooling layers represent high-level features of the input. We decided to add a fully connected layer to use these features to classify the input image into ten classes based on the training dataset. We used softmax activation since it is the most commonly used when there are n number of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_logits_model_1(x):\n",
    "    \"\"\"Compute the logits of the model\"\"\"\n",
    "\n",
    "    n1 = 16\n",
    "    \n",
    "    x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "    # cnn layer 1\n",
    "    ## 5*5 filter with 1*1 stride: hope to caputre local features\n",
    "    W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "    b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "    h_conv1 = tf.nn.relu(tf.add(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME'), b_conv1))\n",
    "    \n",
    "    \n",
    "    # max pool 1\n",
    "    h_pool1_max = tf.nn.max_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # average pool 1\n",
    "    h_pool1_avg = tf.nn.avg_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # combine max pool and average pool\n",
    "    h_pool1_mixed = tf.add(h_pool1_max, h_pool1_avg) * 0.5\n",
    "    \n",
    "    \n",
    "    # fc 1\n",
    "    h_pool1_flat = tf.reshape(h_pool1_mixed, [-1, 32*32*n1]) \n",
    "    W_fc1 = tf.get_variable('W_fc1', shape=[32*32*n1, 10]) # 32*32*16 -> 10\n",
    "    b_fc1 = tf.get_variable('b_fc1', shape=[10])\n",
    "    logits = tf.add(tf.matmul(h_pool1_flat, W_fc1), b_fc1)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = 1\n",
    "dir_name = \"logs/\" + str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0: Training accuracy 0.1190\n",
      "Step   0: Validation accuracy 0.1110\n",
      "Step 500: Training accuracy 0.4400\n",
      "Step 500: Validation accuracy 0.3914\n",
      "Step 1000: Training accuracy 0.4750\n",
      "Step 1000: Validation accuracy 0.4098\n",
      "Step 1500: Training accuracy 0.4850\n",
      "Step 1500: Validation accuracy 0.4064\n",
      "Step 2000: Training accuracy 0.5060\n",
      "Step 2000: Validation accuracy 0.4388\n",
      "Step 2500: Training accuracy 0.5360\n",
      "Step 2500: Validation accuracy 0.4560\n",
      "Step 3000: Training accuracy 0.5550\n",
      "Step 3000: Validation accuracy 0.4554\n",
      "Step 3500: Training accuracy 0.5570\n",
      "Step 3500: Validation accuracy 0.4752\n",
      "Step 4000: Training accuracy 0.5880\n",
      "Step 4000: Validation accuracy 0.4818\n",
      "Step 4500: Training accuracy 0.5860\n",
      "Step 4500: Validation accuracy 0.4804\n",
      "Step 5000: Training accuracy 0.6020\n",
      "Step 5000: Validation accuracy 0.5032\n",
      "Step 5500: Training accuracy 0.6120\n",
      "Step 5500: Validation accuracy 0.4866\n",
      "Step 6000: Training accuracy 0.6260\n",
      "Step 6000: Validation accuracy 0.4906\n",
      "Step 6500: Training accuracy 0.6330\n",
      "Step 6500: Validation accuracy 0.5034\n",
      "Step 7000: Training accuracy 0.6490\n",
      "Step 7000: Validation accuracy 0.5018\n",
      "Step 7500: Training accuracy 0.6550\n",
      "Step 7500: Validation accuracy 0.5242\n",
      "Step 8000: Training accuracy 0.6600\n",
      "Step 8000: Validation accuracy 0.5160\n",
      "Step 8500: Training accuracy 0.6840\n",
      "Step 8500: Validation accuracy 0.5178\n",
      "Step 9000: Training accuracy 0.7050\n",
      "Step 9000: Validation accuracy 0.5184\n",
      "Step 9500: Training accuracy 0.7070\n",
      "Step 9500: Validation accuracy 0.5288\n",
      "Step 10000: Training accuracy 0.6880\n",
      "Step 10000: Validation accuracy 0.5140\n",
      "Step 10500: Training accuracy 0.7070\n",
      "Step 10500: Validation accuracy 0.5162\n",
      "Step 11000: Training accuracy 0.7060\n",
      "Step 11000: Validation accuracy 0.5142\n",
      "Step 11500: Training accuracy 0.7230\n",
      "Step 11500: Validation accuracy 0.5160\n",
      "Step 12000: Training accuracy 0.7520\n",
      "Step 12000: Validation accuracy 0.5248\n",
      "Step 12500: Training accuracy 0.7500\n",
      "Step 12500: Validation accuracy 0.5176\n",
      "Step 13000: Training accuracy 0.7510\n",
      "Step 13000: Validation accuracy 0.5122\n",
      "Step 13500: Training accuracy 0.7560\n",
      "Step 13500: Validation accuracy 0.5084\n",
      "Step 14000: Training accuracy 0.7750\n",
      "Step 14000: Validation accuracy 0.5226\n",
      "Step 14500: Training accuracy 0.7460\n",
      "Step 14500: Validation accuracy 0.5134\n",
      "Step 15000: Training accuracy 0.7710\n",
      "Step 15000: Validation accuracy 0.5138\n",
      "Step 15500: Training accuracy 0.7720\n",
      "Step 15500: Validation accuracy 0.5236\n",
      "Step 16000: Training accuracy 0.7860\n",
      "Step 16000: Validation accuracy 0.5192\n",
      "Step 16500: Training accuracy 0.7830\n",
      "Step 16500: Validation accuracy 0.5208\n",
      "Step 17000: Training accuracy 0.7920\n",
      "Step 17000: Validation accuracy 0.5260\n",
      "Step 17500: Training accuracy 0.7840\n",
      "Step 17500: Validation accuracy 0.5232\n",
      "Step 18000: Training accuracy 0.7780\n",
      "Step 18000: Validation accuracy 0.5096\n",
      "Step 18500: Training accuracy 0.8020\n",
      "Step 18500: Validation accuracy 0.5182\n",
      "Step 19000: Training accuracy 0.8080\n",
      "Step 19000: Validation accuracy 0.5076\n",
      "Step 19500: Training accuracy 0.8150\n",
      "Step 19500: Validation accuracy 0.5228\n",
      "Step 20000: Training accuracy 0.8320\n",
      "Step 20000: Validation accuracy 0.5188\n",
      "Done! Model saved in file: /tmp/model1.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    \n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits_model_1(x)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    with tf.name_scope('opt'):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = opt.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "        summary_op = tf.summary.merge_all()\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "        summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "        summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(20001):\n",
    "            batch = np.floor(np.random.rand(batch_size)*(train_size)).astype(int)\n",
    "            X_batch = x_train[batch,:,:,:].reshape([batch_size,-1])\n",
    "            y_batch = y_train[batch]\n",
    "\n",
    "            # now run\n",
    "            _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y: y_batch})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            if i%100==0:\n",
    "                summary_writer_train.add_summary(summary, i)\n",
    "\n",
    "            # print diagnostics\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_train[0:1000,:,:,:].reshape([1000,-1])\n",
    "                y_batch = y_train[0:1000]\n",
    "                (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y: y_batch})\n",
    "                print(\"\\rStep {0:3d}: Training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_val.reshape([n_val,-1])\n",
    "                y_batch = y_val\n",
    "                (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch, y:y_batch})\n",
    "                print(\"\\rStep {0:3d}: Validation accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                summary_writer_val.add_summary(summary, i)\n",
    "        \n",
    "        save_dir = '/tmp/model'+str(model)+'.ckpt'\n",
    "        save_path = saver.save(sess, save_dir)\n",
    "        print(\"Done! Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 1 Output: \n",
    "Validation accuracy for model 1 after 20000 steps is around 50%, which is not high enough. \n",
    "\n",
    "Although it is much higher than the theory random classifying--10%, we still want to find more accurate model. \n",
    "\n",
    "We guess that the model is too simple since it only contains one convolution and one pooling layer.It may not capture enough features during the classifying since the training accuracy is only around 80% (not completed learning) after 20000 steps. Therefore we will add more layers in next model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 2: Convolutional Layer 1 -> Mixed Max & Average Pooling 1 ->  Convolutional Layer 2 ->  Mixed Max & Average Pooling 2 -> Fully Connected Layer 1 -> Fully Connected Layer 2\n",
    "1. **Convolutional Layer #1:** Applies 5\\*5\\*64 filter and 1\\*1 stride, with ReLU activation function. \n",
    "2. **Mixed Pooling Layer #1:** Performs max pooling with a 3\\*3 filter and stride of 1 and average pooling with a 3\\*3 filter and stride of 1. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "3. **Convolutional Layer #2:** Applies 3\\*3\\*128 filter and 2\\*2 stride, with ReLU activation function. \n",
    "4. **Mixed Pooling Layer #2:** Performs max pooling with a 3\\*3 filter and stride of 2 and average pooling with a 3\\*3 filter and stride of 2. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "5. **Fully Connected Layer #1:** 2048 neurons with ReLU activation\n",
    "6. **Fully Connected Layer #2 (Logits Layer):** 10 neurons, one for each target class (0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic behind this network:\n",
    "This is the second network we tried. \n",
    "1. Since the performance of the first network is not very good with validation accuracy around 50%, we decided to add one more convolutional layer and mix pooling layer to see if there will be any improvement. \n",
    "\n",
    "2. For the second Convolutional Layer, we applied 3\\*3\\*128 filter and 2\\*2 stride. We increased stride in this case because of two reasons. Firstly, we used the stride of 1 in the first convolutional layer to get enough information so we cared less about information loss this time. And we thought that neighboring pixels are often strongly related and two pixels are less correlated if they are further apart from each other. Therefore we decided to increase the stride size in the second convolutional layer in order to get smaller spatial dimensions by making them overlap less. On the other hand, since the filter jump 2 pixels at a time as we slide them around, it will relatively reduce the computational complexity. In addition, we also considered that if we use a big stride, this will definitely lead to high information loss. Therefore, 2\\*2 stride seemed to be a good choice in this case. \n",
    "\n",
    "3. The reason why we used 3\\*3\\*128 filter is that we wanted to control the information loss of applying a larger stride by using a smaller filter size.\n",
    "\n",
    "4. Besides, we also increased stride in second pooling layer. Since this network is more complex than the first one, we wanted to reduce the number of parameters and increased the computation time. And hopefully without lossing much expressivity at the same time. \n",
    "\n",
    "5. In this case, we added one more fully connected layer. Since we applied convolutional layer and mixed pooling layer twice, the mapping became more complex correspondingly. Fully-connected layers are often considered as a semi-independent mapping of features to outputs, therefore we would like to use more than one fully connected layers to give us enough expressive power.   \n",
    "  \n",
    "6. For this fully connected layer, we used ReLU activation. There are two reasons behind this. The first one is higher computational efficiency (train faster for large networks) and almost same accuracy. This is discussed in details in paper called ['ImageNet Classification with Deep Convolutional Neural Networks'](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf). Another reason is that ReLU also helps to alleviate the vanishing gradient problem compared to sigmoid functions. We inspired by [this post](https://dzone.com/articles/a-beginners-guide-to-understanding-convolutional-n-1).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_logits_model_2(x):\n",
    "    \"\"\"Compute the logits of the model\"\"\"\n",
    "\n",
    "    n1 = 64\n",
    "    n2 = 128\n",
    "    \n",
    "    x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "    # cnn layer 1\n",
    "    ## 5*5 filter with 1*1 stride: hope to caputre local features\n",
    "    W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "    b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "    h_conv1 = tf.nn.relu(tf.add(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME'), b_conv1))\n",
    "    \n",
    "    # max pool 1\n",
    "    h_pool1_max = tf.nn.max_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # average pool 1\n",
    "    h_pool1_avg = tf.nn.avg_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # combine maxpool and average pool\n",
    "    h_pool1_mixed = tf.add(h_pool1_max, h_pool1_avg) * 0.5\n",
    "    \n",
    "    \n",
    "    # cnn layer 2\n",
    "    ## 3*3 filter with 2*2 stride: hope to capture distant features\n",
    "    W_conv2 = tf.get_variable('W_conv2', shape=[3, 3, n1, n2]) \n",
    "    b_conv2 = tf.get_variable('b_conv2', shape=[n2])\n",
    "    h_conv2 = tf.nn.relu(tf.add(tf.nn.conv2d(h_pool1_mixed, W_conv2, strides=[1,2,2,1], padding='SAME'), b_conv2))\n",
    "    \n",
    "    # cnn2 size 32*32 -> 16*16 (stride=2*2)\n",
    "    \n",
    "    \n",
    "    # max pool 2\n",
    "    h_pool2_max = tf.nn.max_pool(h_conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # average pool 2\n",
    "    h_pool2_avg = tf.nn.avg_pool(h_conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # combine maxpool and average pool\n",
    "    h_pool2_mixed = tf.add(h_pool2_max, h_pool2_avg) * 0.5\n",
    "    \n",
    "    # pool 2 size 16*16 -> 8*8 (stride=2*2)\n",
    "    \n",
    "    \n",
    "    # fc layer 1 8192 -> 2048\n",
    "    h_conv2_flat = tf.reshape(h_pool2_mixed, [-1, 8*8*n2]) \n",
    "    W_fc1 = tf.get_variable('W_fc1', shape=[8*8*n2, 2048]) # 8192 -> 2048\n",
    "    b_fc1 = tf.get_variable('b_fc1', shape=[2048])\n",
    "    h_fc1 = tf.nn.relu(tf.add(tf.matmul(h_conv2_flat, W_fc1), b_fc1))\n",
    "    \n",
    "    \n",
    "    # softmax 2048 -> 10\n",
    "    W_fc2 = tf.get_variable('W_fc2', shape=[2048, 10]) # 2048 -> 10\n",
    "    b_fc2 = tf.get_variable('b_fc2', shape=[10])\n",
    "    logits = tf.add(tf.matmul(h_fc1, W_fc2), b_fc2)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = 2\n",
    "dir_name = \"logs/\" + str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0: Training accuracy 0.1160\n",
      "Step   0: Validation accuracy 0.1200\n",
      "Step 500: Training accuracy 0.6300\n",
      "Step 500: Validation accuracy 0.5840\n",
      "Step 1000: Training accuracy 0.7340\n",
      "Step 1000: Validation accuracy 0.6450\n",
      "Step 1500: Training accuracy 0.7840\n",
      "Step 1500: Validation accuracy 0.6634\n",
      "Step 2000: Training accuracy 0.8520\n",
      "Step 2000: Validation accuracy 0.6860\n",
      "Step 2500: Training accuracy 0.8930\n",
      "Step 2500: Validation accuracy 0.6966\n",
      "Step 3000: Training accuracy 0.9380\n",
      "Step 3000: Validation accuracy 0.6958\n",
      "Step 3500: Training accuracy 0.9540\n",
      "Step 3500: Validation accuracy 0.7086\n",
      "Step 4000: Training accuracy 0.9670\n",
      "Step 4000: Validation accuracy 0.7148\n",
      "Step 4500: Training accuracy 0.9800\n",
      "Step 4500: Validation accuracy 0.7068\n",
      "Step 5000: Training accuracy 0.9740\n",
      "Step 5000: Validation accuracy 0.7194\n",
      "Step 5500: Training accuracy 0.9730\n",
      "Step 5500: Validation accuracy 0.7040\n",
      "Step 6000: Training accuracy 0.9860\n",
      "Step 6000: Validation accuracy 0.7170\n",
      "Step 6500: Training accuracy 0.9750\n",
      "Step 6500: Validation accuracy 0.6942\n",
      "Step 7000: Training accuracy 0.9820\n",
      "Step 7000: Validation accuracy 0.7084\n",
      "Step 7500: Training accuracy 0.9780\n",
      "Step 7500: Validation accuracy 0.7056\n",
      "Step 8000: Training accuracy 0.9850\n",
      "Step 8000: Validation accuracy 0.7152\n",
      "Step 8500: Training accuracy 0.9930\n",
      "Step 8500: Validation accuracy 0.7136\n",
      "Step 9000: Training accuracy 0.9900\n",
      "Step 9000: Validation accuracy 0.7048\n",
      "Step 9500: Training accuracy 0.9890\n",
      "Step 9500: Validation accuracy 0.7230\n",
      "Step 10000: Training accuracy 0.9930\n",
      "Step 10000: Validation accuracy 0.7114\n",
      "Step 10500: Training accuracy 0.9820\n",
      "Step 10500: Validation accuracy 0.7110\n",
      "Step 11000: Training accuracy 0.9900\n",
      "Step 11000: Validation accuracy 0.7172\n",
      "Step 11500: Training accuracy 0.9870\n",
      "Step 11500: Validation accuracy 0.7070\n",
      "Step 12000: Training accuracy 0.9860\n",
      "Step 12000: Validation accuracy 0.7148\n",
      "Step 12500: Training accuracy 0.9890\n",
      "Step 12500: Validation accuracy 0.7210\n",
      "Step 13000: Training accuracy 0.9910\n",
      "Step 13000: Validation accuracy 0.7118\n",
      "Step 13500: Training accuracy 0.9980\n",
      "Step 13500: Validation accuracy 0.7288\n",
      "Step 14000: Training accuracy 0.9980\n",
      "Step 14000: Validation accuracy 0.7182\n",
      "Step 14500: Training accuracy 0.9980\n",
      "Step 14500: Validation accuracy 0.7128\n",
      "Step 15000: Training accuracy 0.9970\n",
      "Step 15000: Validation accuracy 0.7212\n",
      "Step 15500: Training accuracy 0.9890\n",
      "Step 15500: Validation accuracy 0.7172\n",
      "Step 16000: Training accuracy 0.9950\n",
      "Step 16000: Validation accuracy 0.7150\n",
      "Step 16500: Training accuracy 0.9950\n",
      "Step 16500: Validation accuracy 0.7280\n",
      "Step 17000: Training accuracy 0.9970\n",
      "Step 17000: Validation accuracy 0.7222\n",
      "Step 17500: Training accuracy 1.0000\n",
      "Step 17500: Validation accuracy 0.7280\n",
      "Step 18000: Training accuracy 0.9970\n",
      "Step 18000: Validation accuracy 0.7260\n",
      "Step 18500: Training accuracy 0.9960\n",
      "Step 18500: Validation accuracy 0.7170\n",
      "Step 19000: Training accuracy 0.9960\n",
      "Step 19000: Validation accuracy 0.7240\n",
      "Step 19500: Training accuracy 0.9950\n",
      "Step 19500: Validation accuracy 0.7244\n",
      "Step 20000: Training accuracy 0.9980\n",
      "Step 20000: Validation accuracy 0.7264\n",
      "Done! Model saved in file: /tmp/model2.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    \n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits_model_2(x)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    with tf.name_scope('opt'):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = opt.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "        summary_op = tf.summary.merge_all()\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "        summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "        summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(20001):\n",
    "            batch = np.floor(np.random.rand(batch_size)*(train_size)).astype(int)\n",
    "            X_batch = x_train[batch,:,:,:].reshape([batch_size,-1])\n",
    "            y_batch = y_train[batch]\n",
    "\n",
    "            # now run\n",
    "            _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y: y_batch})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            if i%100==0:\n",
    "                summary_writer_train.add_summary(summary, i)\n",
    "\n",
    "            # print diagnostics\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_train[0:1000,:,:,:].reshape([1000,-1])\n",
    "                y_batch = y_train[0:1000]\n",
    "                (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y: y_batch})\n",
    "                print(\"\\rStep {0:3d}: Training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_val.reshape([n_val,-1])\n",
    "                y_batch = y_val\n",
    "                (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch, y:y_batch})\n",
    "                print(\"\\rStep {0:3d}: Validation accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                summary_writer_val.add_summary(summary, i)\n",
    "                \n",
    "        save_dir = '/tmp/model'+str(model)+'.ckpt'\n",
    "        save_path = saver.save(sess, save_dir)\n",
    "        print(\"Done! Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 2 output\n",
    "After 20000 steps, learning completed (training accuracy >= 95%), and the validation accuracy is around 70%, which is higher than network 1. \n",
    "\n",
    "As shown above, adding more layers in the model 1 increases both training accuracy and the validation accuracy. The validation accuracy increases to around 70%, which means that our guess after model 1 is correct. Then we consider adding more convolutional layers, pooling layers and fully connected layers will capture more features and will these improve it or not? We decide to do it in network 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 3: Convolutional Layer 1 -> Mixed Pooling 1 ->  Convolutional Layer 2 ->  Mixed Pooling 2 -> Convolutional Layer 3 ->  Mixed Pooling 3 -> FC Layer 1 -> FC Layer 2 -> FC Layer 3\n",
    "1. **Convolutional Layer #1:** Applies 5\\*5\\*64 filter and 1\\*1 stride, with ReLU activation function. \n",
    "2. **Mixed Pooling Layer #1:** Performs max pooling with a 3\\*3 filter and stride of 1 and average pooling with a 3\\*3 filter and stride of 1. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "3. **Convolutional Layer #2:** Applies 3\\*3\\*128 filter and 2\\*2 stride, with ReLU activation function. \n",
    "4. **Mixed Pooling Layer #2:** Performs max pooling with a 3\\*3 filter and stride of 2 and average pooling with a 3\\*3 filter and stride of 2. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "5. **Convolutional Layer #3:** Applies 7\\*7\\*512 filter and 1\\*1 stride, with ReLU activation function. \n",
    "6. **Mixed Pooling Layer #3:** Performs max pooling with a 3\\*3 filter and stride of 2 and average pooling with a 3\\*3 filter and stride of 2. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "7. **Fully Connected Layer #1:** 2048 neurons with ReLU activation\n",
    "8. **Fully Connected Layer #2:** 512 neurons with ReLU activation\n",
    "9. **Fully Connected Layer #3 (Logits Layer):** 10 neurons, one for each target class (0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic behind this network:\n",
    "This is the third network we tried. \n",
    "1. Since the performance increased a lot from first network to second network, we decided to repeat the same step by adding one more convolutional layer and mix pooling layer to see if there will be any improvement further. \n",
    "\n",
    "2. For the Convolutional Layer we added, we applied 7\\*7\\*512 filter and 1\\*1 stride since we want to capture the features within broader views. At the same time, we used stride of 1 to reduce the information loss from using a larger filter size. \n",
    "\n",
    "3. We continued to use stride of 2 for third pooling layer because of the same reason explained above. Since this network is even more complex than the last one, we wanted to reduce the number of parameters and increased the computation efficiency as well. And hopefully without lossing much expressivity at the same time. Because there was a huge improvement in the performance, this choice seemed to be a good one. \n",
    "\n",
    "4. In this network, we added one more fully connected layer up to three in total. The logic behind this is same as the last one. Since we kept adding more convolutional layer and mixed pooling layer, the mapping definitely became more complex correspondingly. Therefore we would like to use more fully connected layers to give us enough expressive power.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_logits_model_3(x):\n",
    "    \"\"\"Compute the logits of the model\"\"\"\n",
    "\n",
    "    n1 = 64\n",
    "    n2 = 128\n",
    "    n3 = 512\n",
    "    \n",
    "    x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "    # cnn layer 1\n",
    "    ## 5*5 filter with 1*1 stride: hope to caputre local features\n",
    "    W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "    b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "    h_conv1 = tf.nn.relu(tf.add(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME'), b_conv1))\n",
    "    \n",
    "    # max pool 1\n",
    "    h_pool1_max = tf.nn.max_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # average pool 1\n",
    "    h_pool1_avg = tf.nn.avg_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # combine maxpool and average pool\n",
    "    h_pool1_mixed = tf.add(h_pool1_max, h_pool1_avg) * 0.5\n",
    "    \n",
    "    \n",
    "    # cnn layer 2\n",
    "    ## 3*3 filter with 2*2 stride: hope to capture distant features\n",
    "    W_conv2 = tf.get_variable('W_conv2', shape=[3, 3, n1, n2]) \n",
    "    b_conv2 = tf.get_variable('b_conv2', shape=[n2])\n",
    "    h_conv2 = tf.nn.relu(tf.add(tf.nn.conv2d(h_pool1_mixed, W_conv2, strides=[1,2,2,1], padding='SAME'), b_conv2))\n",
    "    \n",
    "    # cnn2 size 32*32 -> 16*16 (stride=2*2)\n",
    "    \n",
    "    \n",
    "    # max pool 2\n",
    "    h_pool2_max = tf.nn.max_pool(h_conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # average pool 2\n",
    "    h_pool2_avg = tf.nn.avg_pool(h_conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # combine maxpool and average pool\n",
    "    h_pool2_mixed = tf.add(h_pool2_max, h_pool2_avg) * 0.5\n",
    "    \n",
    "    # pool 2 size 16*16 -> 8*8 (stride=2*2)\n",
    "    \n",
    "    # cnn layer 3\n",
    "    ## 7*7 filter with 1*1 stride: hope to capture more distant features\n",
    "    W_conv3 = tf.get_variable('W_conv3', shape=[7, 7, n2, n3]) \n",
    "    b_conv3 = tf.get_variable('b_conv3', shape=[n3])\n",
    "    h_conv3 = tf.nn.relu(tf.add(tf.nn.conv2d(h_pool2_mixed, W_conv3, strides=[1,1,1,1], padding='SAME'), b_conv3))\n",
    "    \n",
    "    # cnn3 size 8*8 -> 8*8 (stride=1*1)\n",
    "    \n",
    "    # max pool 3 (ksize = 3*3)\n",
    "    h_pool3_max = tf.nn.max_pool(h_conv3, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # average pool 2\n",
    "    h_pool3_avg = tf.nn.avg_pool(h_conv3, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # combine maxpool and average pool\n",
    "    h_pool3_mixed = tf.add(h_pool3_max, h_pool3_avg) * 0.5\n",
    "    \n",
    "    # pool 3 size 8*8 -> 4*4 (stride=2*2)\n",
    "    \n",
    "\n",
    "    \n",
    "    # fc layer 1 8192 -> 2048\n",
    "    h_conv2_flat = tf.reshape(h_pool3_mixed, [-1, 4*4*n3]) \n",
    "    W_fc1 = tf.get_variable('W_fc1', shape=[4*4*n3, 2048]) # 8192 -> 2048\n",
    "    b_fc1 = tf.get_variable('b_fc1', shape=[2048])\n",
    "    h_fc1 = tf.nn.relu(tf.add(tf.matmul(h_conv2_flat, W_fc1), b_fc1))\n",
    "    \n",
    "    \n",
    "    # fc layer 2 2048 -> 512\n",
    "    W_fc2 = tf.get_variable('W_fc2', shape=[2048, 512]) # 2048 -> 512\n",
    "    b_fc2 = tf.get_variable('b_fc2', shape=[512])\n",
    "    h_fc2 = tf.nn.relu(tf.add(tf.matmul(h_fc1, W_fc2), b_fc2))\n",
    "    \n",
    "    \n",
    "    # softmax 512 -> 10\n",
    "    W_fc3 = tf.get_variable('W_fc3', shape=[512, 10]) # 512 -> 10\n",
    "    b_fc3 = tf.get_variable('b_fc3', shape=[10])\n",
    "    logits = tf.add(tf.matmul(h_fc2, W_fc3), b_fc3)\n",
    "\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = 3\n",
    "dir_name = \"logs/\" + str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0: Training accuracy 0.1020\n",
      "Step   0: Validation accuracy 0.0986\n",
      "Step 500: Training accuracy 0.6370\n",
      "Step 500: Validation accuracy 0.6174\n",
      "Step 1000: Training accuracy 0.7130\n",
      "Step 1000: Validation accuracy 0.6672\n",
      "Step 1500: Training accuracy 0.7880\n",
      "Step 1500: Validation accuracy 0.6960\n",
      "Step 2000: Training accuracy 0.8250\n",
      "Step 2000: Validation accuracy 0.7192\n",
      "Step 2500: Training accuracy 0.8810\n",
      "Step 2500: Validation accuracy 0.7244\n",
      "Step 3000: Training accuracy 0.9280\n",
      "Step 3000: Validation accuracy 0.7374\n",
      "Step 3500: Training accuracy 0.9410\n",
      "Step 3500: Validation accuracy 0.7226\n",
      "Step 4000: Training accuracy 0.9600\n",
      "Step 4000: Validation accuracy 0.7348\n",
      "Step 4500: Training accuracy 0.9770\n",
      "Step 4500: Validation accuracy 0.7456\n",
      "Step 5000: Training accuracy 0.9690\n",
      "Step 5000: Validation accuracy 0.7300\n",
      "Step 5500: Training accuracy 0.9840\n",
      "Step 5500: Validation accuracy 0.7470\n",
      "Step 6000: Training accuracy 0.9680\n",
      "Step 6000: Validation accuracy 0.7416\n",
      "Step 6500: Training accuracy 0.9800\n",
      "Step 6500: Validation accuracy 0.7370\n",
      "Step 7000: Training accuracy 0.9770\n",
      "Step 7000: Validation accuracy 0.7436\n",
      "Step 7500: Training accuracy 0.9860\n",
      "Step 7500: Validation accuracy 0.7460\n",
      "Step 8000: Training accuracy 0.9840\n",
      "Step 8000: Validation accuracy 0.7466\n",
      "Done! Model saved in file: /tmp/model3.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    \n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits_model_3(x)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    with tf.name_scope('opt'):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = opt.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "        summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "        summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "        summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(8001):\n",
    "            batch = np.floor(np.random.rand(batch_size)*(train_size)).astype(int)\n",
    "            X_batch = x_train[batch,:,:,:].reshape([batch_size,-1])\n",
    "            y_batch = y_train[batch]\n",
    "\n",
    "            # now run\n",
    "            _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y: y_batch})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            if i%100==0:\n",
    "                summary_writer_train.add_summary(summary, i)\n",
    "\n",
    "            # print diagnostics\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_train[0:1000,:,:,:].reshape([1000,-1])\n",
    "                y_batch = y_train[0:1000]\n",
    "                (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y: y_batch})\n",
    "                print(\"\\rStep {0:3d}: Training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_val.reshape([n_val,-1])\n",
    "                y_batch = y_val\n",
    "                (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch, y:y_batch})\n",
    "                print(\"\\rStep {0:3d}: Validation accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                summary_writer_val.add_summary(summary, i)\n",
    "                \n",
    "        save_dir = '/tmp/model'+str(model)+'.ckpt'\n",
    "        save_path = saver.save(sess, save_dir)\n",
    "        print(\"Done! Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 3 output:\n",
    "The network 3 is complex and it takes a lot of time to run it, we decide to reduce the steps to increase the efficiency. And after we try several times, we find 8000 steps is enough since the learning is completed (training accuracy>=97%).The validation accuracy is around 73%-74%, which is 3% higher than network 2.\n",
    "\n",
    "Although the validation accuracy still increases, it only increases 3%, much less than from model 1 to model 2 (20%). Therefore, we think the three convlutional,mixed pooling and fully connected layers model is enough. Adding more layers will not increase too much accuracy comparing to the cost of less efficiency. So we consider add different layers in model 4. To test the layer we add really useful, we decide to add the layers based on model 2 instead of model 3.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 4: Convolutional Layer 1 -> Mixed Pooling 1 ->  Convolutional Layer 2 ->  Mixed Pooling 2 -> FC Layer 1 -> Dropout Layer -> FC Layer 2\n",
    "1. **Convolutional Layer #1:** Applies 5\\*5\\*64 filter and 1\\*1 stride, with ReLU activation function. \n",
    "2. **Mixed Pooling Layer #1:** Performs max pooling with a 3\\*3 filter and stride of 1 and average pooling with a 3\\*3 filter and stride of 1. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "3. **Convolutional Layer #2:** Applies 3\\*3\\*128 filter and 2\\*2 stride, with ReLU activation function. \n",
    "4. **Mixed Pooling Layer #2:** Performs max pooling with a 3\\*3 filter and stride of 2 and average pooling with a 3\\*3 filter and stride of 2. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "5. **Fully Connected Layer #1:** 2048 neurons with ReLU activation\n",
    "6. **Dropout Layer:** with dropout regularization rate of 0.8 (probability of 0.2 that any given element will be dropped during training)\n",
    "7. **Fully Connected Layer #2 (Logits Layer):** 10 neurons, one for each target class (0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic behind this network:\n",
    "This is the fourth network we tried. \n",
    "1. Since the training accuracy of network 3 is very close to 1.0 but the validation accuracy is only 3% higher than the second network. We suspected that network 3 may suffer from overfitting. Therefore we decided to add one dropout layer to alleviate this problem. \n",
    "\n",
    "2. The reason why we add one dropout layer based on network 2 is that we would like to first test on a less complex network and see if adding dropout layer will have a significant effect. By doing this, it will reduce the computational complexity and save us time. And if this method works, we would like to try this on network 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_logits_model_4(x):\n",
    "    \"\"\"Compute the logits of the model\"\"\"\n",
    "\n",
    "    n1 = 64\n",
    "    n2 = 128\n",
    "    \n",
    "    x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "    # cnn layer 1\n",
    "    ## 5*5 filter with 1*1 stride: hope to caputre local features\n",
    "    W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "    b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "    h_conv1 = tf.nn.relu(tf.add(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME'), b_conv1))\n",
    "    \n",
    "    # max pool 1\n",
    "    h_pool1_max = tf.nn.max_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # average pool 1\n",
    "    h_pool1_avg = tf.nn.avg_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # combine maxpool and average pool\n",
    "    h_pool1_mixed = tf.add(h_pool1_max, h_pool1_avg) * 0.5\n",
    "    \n",
    "    \n",
    "    # cnn layer 2\n",
    "    ## 3*3 filter with 2*2 stride: hope to capture distant features\n",
    "    W_conv2 = tf.get_variable('W_conv2', shape=[3, 3, n1, n2]) \n",
    "    b_conv2 = tf.get_variable('b_conv2', shape=[n2])\n",
    "    h_conv2 = tf.nn.relu(tf.add(tf.nn.conv2d(h_pool1_mixed, W_conv2, strides=[1,2,2,1], padding='SAME'), b_conv2))\n",
    "    \n",
    "    # cnn2 size 32*32 -> 16*16 (stride=2*2)\n",
    "    \n",
    "    \n",
    "    # max pool 2\n",
    "    h_pool2_max = tf.nn.max_pool(h_conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # average pool 2\n",
    "    h_pool2_avg = tf.nn.avg_pool(h_conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # combine maxpool and average pool\n",
    "    h_pool2_mixed = tf.add(h_pool2_max, h_pool2_avg) * 0.5\n",
    "    \n",
    "    # pool 2 size 16*16 -> 8*8 (stride=2*2)\n",
    "    \n",
    "    \n",
    "    # fc layer 1 8192 -> 2048\n",
    "    h_conv2_flat = tf.reshape(h_pool2_mixed, [-1, 8*8*n2]) \n",
    "    W_fc1 = tf.get_variable('W_fc1', shape=[8*8*n2, 2048]) # 8192 -> 2048\n",
    "    b_fc1 = tf.get_variable('b_fc1', shape=[2048])\n",
    "    h_fc1 = tf.nn.relu(tf.add(tf.matmul(h_conv2_flat, W_fc1), b_fc1))\n",
    "    \n",
    "    ## add dropout layer\n",
    "    h_fc1_d = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    \n",
    "    # softmax 2048 -> 10\n",
    "    W_fc2 = tf.get_variable('W_fc2', shape=[2048, 10]) # 2048 -> 10\n",
    "    b_fc2 = tf.get_variable('b_fc2', shape=[10])\n",
    "    \n",
    "    logits = tf.add(tf.matmul(h_fc1_d, W_fc2), b_fc2)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = 4\n",
    "dir_name = \"logs/\" + str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0: Training accuracy 0.0880\n",
      "Step   0: Validation accuracy 0.0986\n",
      "Step 500: Training accuracy 0.6240\n",
      "Step 500: Validation accuracy 0.5826\n",
      "Step 1000: Training accuracy 0.7330\n",
      "Step 1000: Validation accuracy 0.6332\n",
      "Step 1500: Training accuracy 0.8210\n",
      "Step 1500: Validation accuracy 0.6810\n",
      "Step 2000: Training accuracy 0.8620\n",
      "Step 2000: Validation accuracy 0.6980\n",
      "Step 2500: Training accuracy 0.8840\n",
      "Step 2500: Validation accuracy 0.7092\n",
      "Step 3000: Training accuracy 0.9250\n",
      "Step 3000: Validation accuracy 0.7166\n",
      "Step 3500: Training accuracy 0.9570\n",
      "Step 3500: Validation accuracy 0.7176\n",
      "Step 4000: Training accuracy 0.9660\n",
      "Step 4000: Validation accuracy 0.7288\n",
      "Step 4500: Training accuracy 0.9650\n",
      "Step 4500: Validation accuracy 0.7282\n",
      "Step 5000: Training accuracy 0.9730\n",
      "Step 5000: Validation accuracy 0.7258\n",
      "Step 5500: Training accuracy 0.9860\n",
      "Step 5500: Validation accuracy 0.7362\n",
      "Step 6000: Training accuracy 0.9870\n",
      "Step 6000: Validation accuracy 0.7288\n",
      "Step 6500: Training accuracy 0.9910\n",
      "Step 6500: Validation accuracy 0.7278\n",
      "Step 7000: Training accuracy 0.9880\n",
      "Step 7000: Validation accuracy 0.7296\n",
      "Step 7500: Training accuracy 0.9880\n",
      "Step 7500: Validation accuracy 0.7336\n",
      "Step 8000: Training accuracy 0.9940\n",
      "Step 8000: Validation accuracy 0.7376\n",
      "Step 8500: Training accuracy 0.9880\n",
      "Step 8500: Validation accuracy 0.7352\n",
      "Step 9000: Training accuracy 0.9930\n",
      "Step 9000: Validation accuracy 0.7426\n",
      "Step 9500: Training accuracy 0.9970\n",
      "Step 9500: Validation accuracy 0.7360\n",
      "Step 10000: Training accuracy 0.9960\n",
      "Step 10000: Validation accuracy 0.7332\n",
      "Step 10500: Training accuracy 0.9950\n",
      "Step 10500: Validation accuracy 0.7316\n",
      "Step 11000: Training accuracy 0.9950\n",
      "Step 11000: Validation accuracy 0.7252\n",
      "Step 11500: Training accuracy 0.9870\n",
      "Step 11500: Validation accuracy 0.7180\n",
      "Step 12000: Training accuracy 0.9970\n",
      "Step 12000: Validation accuracy 0.7290\n",
      "Step 12500: Training accuracy 0.9970\n",
      "Step 12500: Validation accuracy 0.7308\n",
      "Step 13000: Training accuracy 0.9970\n",
      "Step 13000: Validation accuracy 0.7352\n",
      "Step 13500: Training accuracy 0.9980\n",
      "Step 13500: Validation accuracy 0.7400\n",
      "Step 14000: Training accuracy 0.9970\n",
      "Step 14000: Validation accuracy 0.7332\n",
      "Step 14500: Training accuracy 0.9980\n",
      "Step 14500: Validation accuracy 0.7402\n",
      "Step 15000: Training accuracy 0.9970\n",
      "Step 15000: Validation accuracy 0.7466\n",
      "Step 15500: Training accuracy 0.9990\n",
      "Step 15500: Validation accuracy 0.7412\n",
      "Step 16000: Training accuracy 0.9970\n",
      "Step 16000: Validation accuracy 0.7434\n",
      "Step 16500: Training accuracy 0.9990\n",
      "Step 16500: Validation accuracy 0.7466\n",
      "Step 17000: Training accuracy 0.9990\n",
      "Step 17000: Validation accuracy 0.7362\n",
      "Step 17500: Training accuracy 0.9990\n",
      "Step 17500: Validation accuracy 0.7402\n",
      "Step 18000: Training accuracy 0.9970\n",
      "Step 18000: Validation accuracy 0.7370\n",
      "Step 18500: Training accuracy 0.9990\n",
      "Step 18500: Validation accuracy 0.7514\n",
      "Step 19000: Training accuracy 0.9960\n",
      "Step 19000: Validation accuracy 0.7448\n",
      "Step 19500: Training accuracy 1.0000\n",
      "Step 19500: Validation accuracy 0.7398\n",
      "Step 20000: Training accuracy 1.0000\n",
      "Step 20000: Validation accuracy 0.7348\n",
      "Done! Model saved in file: /tmp/model4.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits_model_4(x)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    with tf.name_scope('opt'):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = opt.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "        summary_op = tf.summary.merge_all()\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "        summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "        summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(20001):\n",
    "            batch = np.floor(np.random.rand(batch_size)*(train_size)).astype(int)\n",
    "            X_batch = x_train[batch,:,:,:].reshape([batch_size,-1])\n",
    "            y_batch = y_train[batch]\n",
    "\n",
    "            # now run\n",
    "            _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y: y_batch, keep_prob: 0.8})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            if i%100==0:\n",
    "                summary_writer_train.add_summary(summary, i)\n",
    "\n",
    "            # print diagnostics\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_train[0:1000,:,:,:].reshape([1000,-1])\n",
    "                y_batch = y_train[0:1000]\n",
    "                (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y: y_batch, keep_prob: 1.0})\n",
    "                print(\"\\rStep {0:3d}: Training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_val.reshape([n_val,-1])\n",
    "                y_batch = y_val\n",
    "                (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch, y:y_batch, keep_prob: 1.0})\n",
    "                print(\"\\rStep {0:3d}: Validation accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                summary_writer_val.add_summary(summary, i)\n",
    "                \n",
    "        save_dir = '/tmp/model'+str(model)+'.ckpt'\n",
    "        save_path = saver.save(sess, save_dir)\n",
    "        print(\"Done! Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 4 output:\n",
    "With the dropout layer, the network has the same structure as newtork 2 after 20000 steps, learning completed (training accuracy >= 99%), and the validation accuracy is around 73%-74%, which is higher than network 2 but similar to network 3. \n",
    "\n",
    "Although the increase of the accuracy is not very higher comparing to newtork 2, adding the dropout layer still provides us another methods to increase the accuracy instead of increasing the convolution, mixed pooling and fully connected layers again. Therefore, we consider combining the dropout layer with the newtork 3, which may increase the accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 5: Convolutional Layer 1 -> Mixed Pooling 1 ->  Convolutional Layer 2 ->  Mixed Pooling 2 ->  Convolutional Layer 3 ->  Mixed Pooling 3 ->FC Layer 1 -> Dropout Layer -> FC Layer 2\n",
    "1. **Convolutional Layer #1:** Applies 5\\*5\\*64 filter and 1\\*1 stride, with ReLU activation function. \n",
    "2. **Mixed Pooling Layer #1:** Performs max pooling with a 3\\*3 filter and stride of 1 and average pooling with a 3\\*3 filter and stride of 1. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "3. **Convolutional Layer #2:** Applies 3\\*3\\*128 filter and 2\\*2 stride, with ReLU activation function. \n",
    "4. **Mixed Pooling Layer #2:** Performs max pooling with a 3\\*3 filter and stride of 2 and average pooling with a 3\\*3 filter and stride of 2. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "5. **Convolutional Layer #3:** Applies 7\\*7\\*512 filter and 1\\*1 stride, with ReLU activation function. \n",
    "6. **Mixed Pooling Layer #3:** Performs max pooling with a 3\\*3 filter and stride of 2 and average pooling with a 3\\*3 filter and stride of 2. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "5. **Fully Connected Layer #1:** 2048 neurons with ReLU activation\n",
    "6. **Fully Connected Layer #2:** 512 neurons with ReLU activation\n",
    "7. **Dropout Layer:** with dropout regularization rate of 0.8 (probability of 0.2 that any given element will be dropped during training)\n",
    "8. **Fully Connected Layer #3 (Logits Layer):** 10 neurons, one for each target class (0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic behind this network:\n",
    "This is the fifth network we tried. \n",
    "1. Since the performance of network 4 is better than the performance of network 2, we decided to add one dropout layer based on network 3 and see if doing this way will alleviate the overfitting problem and further improve the performance of network 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_logits_model_5(x):\n",
    "    \"\"\"Compute the logits of the model\"\"\"\n",
    "\n",
    "    n1 = 64\n",
    "    n2 = 128\n",
    "    n3 = 512\n",
    "    \n",
    "    x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "    # cnn layer 1\n",
    "    ## 5*5 filter with 1*1 stride: hope to caputre local features\n",
    "    W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "    b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "    h_conv1 = tf.nn.relu(tf.add(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME'), b_conv1))\n",
    "    \n",
    "    # max pool 1\n",
    "    h_pool1_max = tf.nn.max_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # average pool 1\n",
    "    h_pool1_avg = tf.nn.avg_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # combine maxpool and average pool\n",
    "    h_pool1_mixed = tf.add(h_pool1_max, h_pool1_avg) * 0.5\n",
    "    \n",
    "    \n",
    "    # cnn layer 2\n",
    "    ## 3*3 filter with 2*2 stride: hope to capture distant features\n",
    "    W_conv2 = tf.get_variable('W_conv2', shape=[3, 3, n1, n2]) \n",
    "    b_conv2 = tf.get_variable('b_conv2', shape=[n2])\n",
    "    h_conv2 = tf.nn.relu(tf.add(tf.nn.conv2d(h_pool1_mixed, W_conv2, strides=[1,2,2,1], padding='SAME'), b_conv2))\n",
    "    \n",
    "    # cnn2 size 32*32 -> 16*16 (stride=2*2)\n",
    "    \n",
    "    \n",
    "    # max pool 2\n",
    "    h_pool2_max = tf.nn.max_pool(h_conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # average pool 2\n",
    "    h_pool2_avg = tf.nn.avg_pool(h_conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # combine maxpool and average pool\n",
    "    h_pool2_mixed = tf.add(h_pool2_max, h_pool2_avg) * 0.5\n",
    "    \n",
    "    # pool 2 size 16*16 -> 8*8 (stride=2*2)\n",
    "    \n",
    "    # cnn layer 3\n",
    "    ## 7*7 filter with 1*1 stride: hope to capture more distant features\n",
    "    W_conv3 = tf.get_variable('W_conv3', shape=[7, 7, n2, n3]) \n",
    "    b_conv3 = tf.get_variable('b_conv3', shape=[n3])\n",
    "    h_conv3 = tf.nn.relu(tf.add(tf.nn.conv2d(h_pool2_mixed, W_conv3, strides=[1,1,1,1], padding='SAME'), b_conv3))\n",
    "    \n",
    "    # cnn3 size 8*8 -> 8*8 (stride=1*1)\n",
    "    \n",
    "    # max pool 3 (ksize = 3*3)\n",
    "    h_pool3_max = tf.nn.max_pool(h_conv3, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # average pool 2\n",
    "    h_pool3_avg = tf.nn.avg_pool(h_conv3, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # combine maxpool and average pool\n",
    "    h_pool3_mixed = tf.add(h_pool3_max, h_pool3_avg) * 0.5\n",
    "    \n",
    "    # pool 3 size 8*8 -> 4*4 (stride=2*2)\n",
    "    \n",
    "\n",
    "    \n",
    "    # fc layer 1 8192 -> 2048\n",
    "    h_conv2_flat = tf.reshape(h_pool3_mixed, [-1, 4*4*n3]) \n",
    "    W_fc1 = tf.get_variable('W_fc1', shape=[4*4*n3, 2048]) # 8192 -> 2048\n",
    "    b_fc1 = tf.get_variable('b_fc1', shape=[2048])\n",
    "    h_fc1 = tf.nn.relu(tf.add(tf.matmul(h_conv2_flat, W_fc1), b_fc1))\n",
    "\n",
    "    \n",
    "    # fc layer 2 2048 -> 512\n",
    "    W_fc2 = tf.get_variable('W_fc2', shape=[2048, 512]) # 2048 -> 512\n",
    "    b_fc2 = tf.get_variable('b_fc2', shape=[512])\n",
    "    h_fc2 = tf.nn.relu(tf.add(tf.matmul(h_fc1, W_fc2), b_fc2))\n",
    "    \n",
    "    \n",
    "    ## add dropouter layer \n",
    "    h_fc2_d = tf.nn.dropout(h_fc2, keep_prob)\n",
    "    \n",
    "    \n",
    "    # softmax 512 -> 10\n",
    "    W_fc3 = tf.get_variable('W_fc3', shape=[512, 10]) # 512 -> 10\n",
    "    b_fc3 = tf.get_variable('b_fc3', shape=[10])\n",
    "    logits = tf.add(tf.matmul(h_fc2_d, W_fc3), b_fc3)\n",
    "\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = 5\n",
    "dir_name = \"logs/\" + str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0: Training accuracy 0.0910\n",
      "Step   0: Validation accuracy 0.1036\n",
      "Step 500: Training accuracy 0.6030\n",
      "Step 500: Validation accuracy 0.5774\n",
      "Step 1000: Training accuracy 0.6690\n",
      "Step 1000: Validation accuracy 0.6452\n",
      "Step 1500: Training accuracy 0.7700\n",
      "Step 1500: Validation accuracy 0.6950\n",
      "Step 2000: Training accuracy 0.8400\n",
      "Step 2000: Validation accuracy 0.7104\n",
      "Step 2500: Training accuracy 0.8720\n",
      "Step 2500: Validation accuracy 0.7182\n",
      "Step 3000: Training accuracy 0.9080\n",
      "Step 3000: Validation accuracy 0.7268\n",
      "Step 3500: Training accuracy 0.9350\n",
      "Step 3500: Validation accuracy 0.7388\n",
      "Step 4000: Training accuracy 0.9560\n",
      "Step 4000: Validation accuracy 0.7396\n",
      "Step 4500: Training accuracy 0.9780\n",
      "Step 4500: Validation accuracy 0.7434\n",
      "Step 5000: Training accuracy 0.9640\n",
      "Step 5000: Validation accuracy 0.7438\n",
      "Step 5500: Training accuracy 0.9710\n",
      "Step 5500: Validation accuracy 0.7434\n",
      "Step 6000: Training accuracy 0.9790\n",
      "Step 6000: Validation accuracy 0.7396\n",
      "Step 6500: Training accuracy 0.9880\n",
      "Step 6500: Validation accuracy 0.7424\n",
      "Step 7000: Training accuracy 0.9850\n",
      "Step 7000: Validation accuracy 0.7418\n",
      "Step 7500: Training accuracy 0.9950\n",
      "Step 7500: Validation accuracy 0.7424\n",
      "Step 8000: Training accuracy 0.9880\n",
      "Step 8000: Validation accuracy 0.7416\n",
      "Done! Model saved in file: /tmp/model5.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits_model_5(x)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    with tf.name_scope('opt'):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = opt.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "        summary_op = tf.summary.merge_all()\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "        summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "        summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(8001):\n",
    "            batch = np.floor(np.random.rand(batch_size)*(train_size)).astype(int)\n",
    "            X_batch = x_train[batch,:,:,:].reshape([batch_size,-1])\n",
    "            y_batch = y_train[batch]\n",
    "\n",
    "            # now run\n",
    "            _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y: y_batch, keep_prob: 0.8})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            if i%100==0:\n",
    "                summary_writer_train.add_summary(summary, i)\n",
    "\n",
    "            # print diagnostics\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_train[0:1000,:,:,:].reshape([1000,-1])\n",
    "                y_batch = y_train[0:1000]\n",
    "                (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y: y_batch, keep_prob: 1.0})\n",
    "                print(\"\\rStep {0:3d}: Training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_val.reshape([n_val,-1])\n",
    "                y_batch = y_val\n",
    "                (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch, y:y_batch, keep_prob: 1.0})\n",
    "                print(\"\\rStep {0:3d}: Validation accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                summary_writer_val.add_summary(summary, i)\n",
    "                \n",
    "        save_dir = '/tmp/model'+str(model)+'.ckpt'\n",
    "        save_path = saver.save(sess, save_dir)\n",
    "        print(\"Done! Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 5 Output:\n",
    "\n",
    "Similar to the newtork 3, the training accuracy suggests that the model completes the learning after 8000 steps. With the dropout layer, the network has the same structure as newtork 3 after 8000 steps, learning completed (training accuracy >= 97%), and the validation accuracy is around 74%, which is similar to network 3 and network 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: \n",
    "\n",
    "Since the performance of network 3, network 4 and network 5 are very similar based on validation data, we are interested in the performance of these three networks using the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model performance with testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Newtork 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model3.ckpt\n",
      "Test Accuracy for Newtork 3:  0.7437\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "save_dir = '/tmp/model'+str(model)+'.ckpt'\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    \n",
    "    ## handle models with dropout\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    with tf.name_scope('model'):\n",
    "        \n",
    "        ## choose correct model here\n",
    "        logits = compute_logits_model_3(x)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "\n",
    "    with tf.name_scope('opt'):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = opt.minimize(loss)\n",
    "\n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Restore variables from disk.\n",
    "        saver.restore(sess, save_dir)\n",
    "        X_batch = x_test.reshape([x_test.shape[0],-1])\n",
    "        y_batch = y_test\n",
    "        \n",
    "        ## feed dropout if needed\n",
    "        test_error = sess.run((accuracy), {x:X_batch, y:y_batch, keep_prob: 1.0})\n",
    "\n",
    "        print(\"Test Accuracy for Newtork \" + str(model) + \": {0: 0.4f}\".format(test_error))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Newtork 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model4.ckpt\n",
      "Test Accuracy for Newtork 4:  0.7282\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "save_dir = '/tmp/model'+str(model)+'.ckpt'\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    \n",
    "    ## handle models with dropout\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    with tf.name_scope('model'):\n",
    "        \n",
    "        ## choose correct model here\n",
    "        logits = compute_logits_model_4(x)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "\n",
    "    with tf.name_scope('opt'):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = opt.minimize(loss)\n",
    "\n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Restore variables from disk.\n",
    "        saver.restore(sess, save_dir)\n",
    "        X_batch = x_test.reshape([x_test.shape[0],-1])\n",
    "        y_batch = y_test\n",
    "        \n",
    "        ## feed dropout if needed\n",
    "        test_error = sess.run((accuracy), {x:X_batch, y:y_batch, keep_prob: 1.0})\n",
    "\n",
    "        print(\"Test Accuracy for Newtork \" + str(model) + \": {0: 0.4f}\".format(test_error))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Newtork 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model5.ckpt\n",
      "Test Accuracy for Newtork 5:  0.7402\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "save_dir = '/tmp/model'+str(model)+'.ckpt'\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    \n",
    "    ## handle models with dropout\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    with tf.name_scope('model'):\n",
    "        \n",
    "        ## choose correct model here\n",
    "        logits = compute_logits_model_5(x)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "\n",
    "    with tf.name_scope('opt'):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = opt.minimize(loss)\n",
    "\n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Restore variables from disk.\n",
    "        saver.restore(sess, save_dir)\n",
    "        X_batch = x_test.reshape([x_test.shape[0],-1])\n",
    "        y_batch = y_test\n",
    "        \n",
    "        ## feed dropout if needed\n",
    "        test_error = sess.run((accuracy), {x:X_batch, y:y_batch, keep_prob: 1.0})\n",
    "\n",
    "        print(\"Test Accuracy for Newtork \" + str(model) + \": {0: 0.4f}\".format(test_error))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: \n",
    "\n",
    "1. Based on the test accuracy of the three networks above, we found that the network 3 has the highest accuracy, and it is even higher than network 5, which has the same structure with an extra dropout layer. From our observations, we conclude that the mixed pooling strategy does not cause overfitting, and pooling layers are not necessary for the networks that employed mixed pooling.\n",
    "\n",
    "2. Among our 5 networks, network 3 (Convolutional Layer 1 -> Mixed Pooling 1 ->  Convolutional Layer 2 ->  Mixed Pooling 2 -> Convolutional Layer 3 ->  Mixed Pooling 3 -> FC Layer 1 -> FC Layer 2 -> FC Layer 3) is the best model, which achieves 74.37% test accuracy. \n",
    "\n",
    "3. However, network 3 took 2 more hours to be trained than network 5 did, but the increase in test and validation accuracy is very limited. Thus, we can conclude that the network 3 is the most efficient one among the 5 networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://image.ibb.co/bW1Sem/Screen_Shot_2017_12_18_at_10_32_56_AM.png\" alt=\"Screen_Shot_2017_12_18_at_10_32_56_AM\" border=\"0\">\n",
    "<img src=\"https://image.ibb.co/e7cVX6/Screen_Shot_2017_12_18_at_10_23_09_AM.png\" alt=\"Screen_Shot_2017_12_18_at_10_23_09_AM\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Another Approach: Exponential Linear Units (ELUs) activation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 6: Elu model based on model 1\n",
    "1. **Convolutional Layer:** Applies 5\\*5\\*16 filter and 1\\*1 stride, with elu activation function. \n",
    "2. **Mixed Pooling Layer:** Performs max pooling with a 3\\*3 filter and stride of 1 and average pooling with a 3\\*3 filter and stride of 1. Then uses mix 50/50, which is $f_{mix}(x) = 0.5f_{max}(x) + 0.5f_{avg}(x)$. \n",
    "3. **Fully Connected Layer:** Implements the flatten function to change the dimension and the uses softmax activation.\n",
    "\n",
    "### Logic behind this network:\n",
    "1. we want to test whether the elu activation function may provide the better performance on both accuracy and the speed. So we choose network 1 as the base model and comparing these two network. \n",
    "2. Since we want to compare the behavior of the two networks only depending on the activation function, we do not change the parameters used in network 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_logits_model_6(x):\n",
    "    \"\"\"Compute the logits of the model\"\"\"\n",
    "\n",
    "    n1 = 16\n",
    "    \n",
    "    x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "    # cnn layer 1\n",
    "    ## 5*5 filter with 1*1 stride: hope to caputre local features\n",
    "    W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "    b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "    h_conv1 = tf.nn.elu(tf.add(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME'), b_conv1))\n",
    "    \n",
    "    \n",
    "    # max pool 1\n",
    "    h_pool1_max = tf.nn.max_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # average pool 1\n",
    "    h_pool1_avg = tf.nn.avg_pool(h_conv1, ksize=[1,3,3,1], strides=[1,1,1,1], padding=\"SAME\")\n",
    "    # combine max pool and average pool\n",
    "    h_pool1_mixed = tf.add(h_pool1_max, h_pool1_avg) * 0.5\n",
    "    \n",
    "    \n",
    "    # fc 1\n",
    "    h_pool1_flat = tf.reshape(h_pool1_mixed, [-1, 32*32*n1]) \n",
    "    W_fc1 = tf.get_variable('W_fc1', shape=[32*32*n1, 10]) # 32*32*16 -> 10\n",
    "    b_fc1 = tf.get_variable('b_fc1', shape=[10])\n",
    "    logits = tf.add(tf.matmul(h_pool1_flat, W_fc1), b_fc1)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "model = 6\n",
    "dir_name = \"logs/\" + str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0: Training accuracy 0.0930\n",
      "Step   0: Validation accuracy 0.0820\n",
      "Step 500: Training accuracy 0.3970\n",
      "Step 500: Validation accuracy 0.3894\n",
      "Step 1000: Training accuracy 0.4290\n",
      "Step 1000: Validation accuracy 0.3852\n",
      "Step 1500: Training accuracy 0.4450\n",
      "Step 1500: Validation accuracy 0.4012\n",
      "Step 2000: Training accuracy 0.4610\n",
      "Step 2000: Validation accuracy 0.4054\n",
      "Step 2500: Training accuracy 0.5020\n",
      "Step 2500: Validation accuracy 0.4240\n",
      "Step 3000: Training accuracy 0.5320\n",
      "Step 3000: Validation accuracy 0.4400\n",
      "Step 3500: Training accuracy 0.5470\n",
      "Step 3500: Validation accuracy 0.4530\n",
      "Step 4000: Training accuracy 0.5610\n",
      "Step 4000: Validation accuracy 0.4762\n",
      "Step 4500: Training accuracy 0.5730\n",
      "Step 4500: Validation accuracy 0.4882\n",
      "Step 5000: Training accuracy 0.6040\n",
      "Step 5000: Validation accuracy 0.4946\n",
      "Step 5500: Training accuracy 0.6450\n",
      "Step 5500: Validation accuracy 0.5040\n",
      "Step 6000: Training accuracy 0.6390\n",
      "Step 6000: Validation accuracy 0.5026\n",
      "Step 6500: Training accuracy 0.6710\n",
      "Step 6500: Validation accuracy 0.5090\n",
      "Step 7000: Training accuracy 0.6820\n",
      "Step 7000: Validation accuracy 0.5172\n",
      "Step 7500: Training accuracy 0.6850\n",
      "Step 7500: Validation accuracy 0.5144\n",
      "Step 8000: Training accuracy 0.6940\n",
      "Step 8000: Validation accuracy 0.5224\n",
      "Step 8500: Training accuracy 0.7120\n",
      "Step 8500: Validation accuracy 0.5164\n",
      "Step 9000: Training accuracy 0.7030\n",
      "Step 9000: Validation accuracy 0.5224\n",
      "Step 9500: Training accuracy 0.7360\n",
      "Step 9500: Validation accuracy 0.5264\n",
      "Step 10000: Training accuracy 0.7540\n",
      "Step 10000: Validation accuracy 0.5326\n",
      "Step 10500: Training accuracy 0.7290\n",
      "Step 10500: Validation accuracy 0.5294\n",
      "Step 11000: Training accuracy 0.7430\n",
      "Step 11000: Validation accuracy 0.5250\n",
      "Step 11500: Training accuracy 0.7390\n",
      "Step 11500: Validation accuracy 0.5244\n",
      "Step 12000: Training accuracy 0.7430\n",
      "Step 12000: Validation accuracy 0.5148\n",
      "Step 12500: Training accuracy 0.7680\n",
      "Step 12500: Validation accuracy 0.5300\n",
      "Step 13000: Training accuracy 0.7750\n",
      "Step 13000: Validation accuracy 0.5396\n",
      "Step 13500: Training accuracy 0.7780\n",
      "Step 13500: Validation accuracy 0.5304\n",
      "Step 14000: Training accuracy 0.7960\n",
      "Step 14000: Validation accuracy 0.5344\n",
      "Step 14500: Training accuracy 0.7860\n",
      "Step 14500: Validation accuracy 0.5262\n",
      "Step 15000: Training accuracy 0.8110\n",
      "Step 15000: Validation accuracy 0.5278\n",
      "Step 15500: Training accuracy 0.7940\n",
      "Step 15500: Validation accuracy 0.5344\n",
      "Step 16000: Training accuracy 0.8000\n",
      "Step 16000: Validation accuracy 0.5286\n",
      "Step 16500: Training accuracy 0.8050\n",
      "Step 16500: Validation accuracy 0.5308\n",
      "Step 17000: Training accuracy 0.8060\n",
      "Step 17000: Validation accuracy 0.5238\n",
      "Step 17500: Training accuracy 0.8270\n",
      "Step 17500: Validation accuracy 0.5286\n",
      "Step 18000: Training accuracy 0.7950\n",
      "Step 18000: Validation accuracy 0.5172\n",
      "Step 18500: Training accuracy 0.7950\n",
      "Step 18500: Validation accuracy 0.5234\n",
      "Step 19000: Training accuracy 0.8040\n",
      "Step 19000: Validation accuracy 0.5236\n",
      "Step 19500: Training accuracy 0.8200\n",
      "Step 19500: Validation accuracy 0.5294\n",
      "Step 20000: Training accuracy 0.8140\n",
      "Step 20000: Validation accuracy 0.5190\n",
      "Done! Model saved in file: /tmp/model6.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    \n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits_model_6(x)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    with tf.name_scope('opt'):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = opt.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "        summary_op = tf.summary.merge_all()\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "        summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "        summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(20001):\n",
    "            batch = np.floor(np.random.rand(batch_size)*(train_size)).astype(int)\n",
    "            X_batch = x_train[batch,:,:,:].reshape([batch_size,-1])\n",
    "            y_batch = y_train[batch]\n",
    "\n",
    "            # now run\n",
    "            _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y: y_batch})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            if i%100==0:\n",
    "                summary_writer_train.add_summary(summary, i)\n",
    "\n",
    "            # print diagnostics\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_train[0:1000,:,:,:].reshape([1000,-1])\n",
    "                y_batch = y_train[0:1000]\n",
    "                (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y: y_batch})\n",
    "                print(\"\\rStep {0:3d}: Training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "\n",
    "            if i%500 == 0:\n",
    "                X_batch = x_val.reshape([n_val,-1])\n",
    "                y_batch = y_val\n",
    "                (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch, y:y_batch})\n",
    "                print(\"\\rStep {0:3d}: Validation accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                summary_writer_val.add_summary(summary, i)\n",
    "        \n",
    "        save_dir = '/tmp/model'+str(model)+'.ckpt'\n",
    "        save_path = saver.save(sess, save_dir)\n",
    "        print(\"Done! Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 6 output:\n",
    "Comparing to the network 1, we can see that the elu model really increases the validation accuracy. Although it does not increase a lot (near 1%), it still gives us a good idea to improve our network 5. However, the training time suggests that the elu model does not run faster as the paper states. We infer the reason is that we do not find and use the optimal parameters as in the paper.  \n",
    "\n",
    "Unfortunately, due to the limited time, we decide to improve our model 5 by using this method in our future study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://image.ibb.co/hd3jQR/Screen_Shot_2017_12_18_at_10_33_41_AM.png\" alt=\"Screen_Shot_2017_12_18_at_10_33_41_AM\" border=\"0\">\n",
    "\n",
    "<img src=\"https://image.ibb.co/eMH8Km/Screen_Shot_2017_12_18_at_9_03_29_AM.png\" alt=\"Screen_Shot_2017_12_18_at_9_03_29_AM\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further study\n",
    "1. **Use only convolutional layers and discard the pooling layer** We found that some people dislike pooling operation and they argue that by repeating convolutional layers without pooling layer. For example, in paper Striving for Simplicity: The All Convolutional Net, the author uses larger stride in convolutional layer to reduce the size of representation instead of using pooling layers. We would like to try this method if we have extra time and more powerful hardware (faster GPU). \n",
    "\n",
    "2. **Learning mixing proportion for \"mixed\" max-average pooling** In this project, we only used the simplest 50/50 mix pooling. In the [paper](https://arxiv.org/pdf/1509.08985.pdf), the author talked about learning mixing proportion parameters $a_{l}$ in the formula $f_{mix}(x) = a_{l} * f_{max}(x) + (1- a_{l}) *f_{avg}(x)$ from the data by different options: (1) per net, (2) per layer, (3) per layer/region being pooled, (4) per layer/channel and (5) per layer/region/channel combination. We will definitely try those out if we have extra time. \n",
    "\n",
    "3. **Maxout** There are many articles talked about maxout. For example, this [paper](http://proceedings.mlr.press/v28/goodfellow13.pdf) provides a very detailed description. The maxout model is simply a feed-forward achitecture and people often use Conv. maxout + dropout to achieve lower test set misclassification rates. We think this will be a good option to try if we have more time.\n",
    "\n",
    "4. **ELUs**  There are some articles talking about the elu (Exponential Linear Units) model. For example, this [paper](https://arxiv.org/abs/1511.07289) provides us a detail description of elu. The elu functions is $f(x)=a_{l}*(exp(x)-1)$ for $x<0$ and $f(x)=x$ for $x>0$. The paper states that the performance of elu is better on both efficiency and accuracy. We found that ELU activation would out-performance Relu activation in a longer period of time. However, this is only for a simple network structure. We would like to try ELU on more complicated networks to compare their performances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. The CIFAR-10 dataset: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "2. Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree: https://arxiv.org/pdf/1509.08985.pdf\n",
    "3. ImageNet Classification with Deep Convolutional Neural Networks: http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf\n",
    "4. A post written by Adit Deshpande: https://dzone.com/articles/a-beginners-guide-to-understanding-convolutional-n-1\n",
    "5. Maxout Networks: http://proceedings.mlr.press/v28/goodfellow13.pdf\n",
    "6. Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUS): https://arxiv.org/pdf/1511.07289.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
